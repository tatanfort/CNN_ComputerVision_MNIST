{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation de réseaux de neuronnes profonds et de convolutions pour la classification d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce notebook est de comparer différentes architectures afin d'obtenir le meilleur score prossible de prédiction sur le dataset MNIST dans le cadre de la compétition Kaggle associée.\n",
    "La librairie utilisée est Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleur score final obtenu: accuracy données test 0.99757 pour 138,682 parametres. TOP 4% Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Activation, Flatten, MaxPooling2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import et traitemment du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Depuis le dataset MNIST de Keras\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "n_cols=X_train.shape[1]*X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], n_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], n_cols)\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "taille_batch=20\n",
    "lr=[0.000001,0.01,1] #different lr à tester\n",
    "early_stopping = EarlyStopping(patience=2)\n",
    "\n",
    "#Depuis le dataset fourni par Kaggle\n",
    "data_train_kaggle=pd.read_csv(\"/Users/nathanredin/Downloads/digit-recognizer/train.csv\")\n",
    "data_train_kaggle=np.array(data_train_kaggle)\n",
    "data_test_kaggle=pd.read_csv(\"/Users/nathanredin/Downloads/digit-recognizer/test.csv\")\n",
    "data_test_kaggle=np.array(data_test_kaggle)\n",
    "X_test_kaggle=data_test_kaggle.reshape(28000,28,28,1)\n",
    "y_train_kaggle=data_train_kaggle[:,0]\n",
    "X_train_kaggle=data_train_kaggle[:,1:42000]\n",
    "X_train_kaggle=X_train_kaggle.reshape(42000,28,28,1)\n",
    "y_train_kaggle = np_utils.to_categorical(y_train_kaggle, 10)\n",
    "X_train_kaggle=X_train_kaggle/255\n",
    "X_test_kaggle=X_test_kaggle/255\n",
    "\n",
    "\n",
    "#nb: j'ai utilisé l'intégralité du dataset MNIST pour entrainer les models:\n",
    "#X_train = np.concatenate((X_train, X_test))\n",
    "#y_train = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous allons entrainer plusieurs fois le même model et pour la lisibilité de ce notebook,\n",
    "je crée une fonction réinitialisant les poids du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model):\n",
    "    session = keras.backend.get_session()\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation d'un reseau basique (type RBM) et entrainement sur les données d'apprentissage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                1650      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 27,280\n",
      "Trainable params: 27,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#premiere couche\n",
    "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
    "#seconde couche\n",
    "model.add(Dense(50, activation='relu'))\n",
    "#derniere couche\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=taille_batch,epochs=10)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Réseau à convolutions (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 10)        100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 10)        910       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1210)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                38752     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                1650      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 41,922\n",
      "Trainable params: 41,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.reshape(60000,28,28,1)    #l'entrée d'une couche de convolutions doit etre en format matriciel (ici 28x28)\n",
    "img_rows=X_train.shape[1]\n",
    "img_cols=X_train.shape[2]\n",
    "\n",
    "# Initialisation du model\n",
    "model = Sequential()\n",
    "\n",
    "# ajout d'une convolution:\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu',\n",
    "               input_shape=[img_rows,img_cols,1]))\n",
    "#pour réduire le temps de calcule et la qualité du modele on peut jouer sur le padding et le strides ou encore utiliser un noyau dilaté...\n",
    "\n",
    "#ajout d'un MaxPooling pour réduire le nombres de parametres\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2),padding='valid'))\n",
    "\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu',\n",
    "               input_shape=[img_rows,img_cols,1]))\n",
    "\n",
    "# applatissage et concaténation des features map\n",
    "model.add(Flatten())\n",
    "\n",
    "#premiere couche\n",
    "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
    "#seconde couche\n",
    "model.add(Dense(50, activation='relu'))\n",
    "#derniere couche\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=taille_batch,epochs=10)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Avec cette architecture, je me retrouve classé top 29% seulement alors qu'on a une accuracy de 99.9% sur les données d'apprentissage, contre 99.3114% sur les données test (sans le maxpool et le second cnn), et 98.8871% avec. Je soupçonne donc un leger overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Afin d'éviter l'overfitting: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut deja commencer par plot la validation-loss curve selon le nombre d'epochs effectués afin d'avoir une idée de l'évolution du model durant la phase d'apprentissage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reset_weights(model)\n",
    "training = model.fit(X_train, y_train, batch_size=taille_batch,epochs=10,verbose=0,validation_split=0.2)\n",
    "history = training.history\n",
    "plt.plot(history['loss'])\n",
    "# Plot the validation loss\n",
    "plt.plot(history['val_loss'])\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que rapidement (après 4 à 5 epochs) la valeur de l'entropie croisée sur les données test stagne et ré-augmente. C'est donc qu'il y a overfiting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajouter un callback dans le model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo\n"
     ]
    }
   ],
   "source": [
    "reset_weights(model)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=2)\n",
    "training = model.fit(X_train, y_train, batch_size=taille_batch,epochs=10,callbacks=[early_stopping],validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stocker les poids après chaque training et recuperer ceux qui minimisent la val_loss grace à la methode Callback de Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_weights(model)\n",
    "\n",
    "checkpoint=ModelCheckpoint('weights.hdf5',monitor='val_loss',save_best_only=True) #a executer avant l'apprentissage\n",
    "callback_list=[checkpoint]\n",
    "training = model.fit(X_train, y_train, batch_size=taille_batch,epochs=10,callbacks=callback_list,validation_split=0.2)\n",
    "\n",
    "model.load_weights('weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régularisation par ajout d'une couche dropout et batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 5, 5, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 5, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 138,682\n",
      "Trainable params: 138,330\n",
      "Non-trainable params: 352\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train=X_train.reshape(70000,28,28,1)\n",
    "img_rows=x_train.shape[1]\n",
    "img_cols=x_train.shape[2]\n",
    "\n",
    "#le nombre de parametres étant réduit par les 2 couches de MaxPooling et le Dropout, on peut augmenter le nombre de noyaux sur les couches de convolutions.\n",
    "#On peut également créer une architecture plus profonde:\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=3, activation='relu',\n",
    "               input_shape=[img_rows,img_cols,1], padding='same'))\n",
    "model.add(Conv2D(16, kernel_size=3, activation='relu',\n",
    "               input_shape=[img_rows,img_cols,1], padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),padding='valid'))\n",
    "# Ajout d'un dropout \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu',\n",
    "               input_shape=[img_rows,img_cols,1], padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu',\n",
    "               input_shape=[img_rows,img_cols,1], padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),padding='valid'))\n",
    "# Ajout d'un dropout \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu',\n",
    "               input_shape=[img_rows,img_cols,1]))\n",
    "\n",
    "# Ajout d'une couche de normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "#stocker les poids après chaque training et recuperer ceux qui minimisent la val_loss grace à la methode Callback de Keras\n",
    "checkpoint=ModelCheckpoint('weights.hdf5',monitor='val_loss',save_best_only=True) #a executer avant l'apprentissage\n",
    "callback_list=[checkpoint]\n",
    "training = model.fit(x_train, y_train, batch_size=taille_batch,epochs=30,callbacks=callback_list,validation_split=0.2)\n",
    "\n",
    "model.load_weights('weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un apprentissage sur 30 epochs permet d'améliorer le score sur les données test (accuracy 0.99757) ce qui m'a permit d'améliorer le ranking kaggle: top 4% \n",
    "avec un temps de processing relativement court: 8mn d'apprentissage\n",
    "\n",
    "Machine: \n",
    "\n",
    "CPU 2 coeurs Intel Core i5 cadencé à 2.7 GHz\n",
    "\n",
    "GPU Intel Iris Graphics 6100 1536 Mo\n",
    "\n",
    "https://www.kaggle.com/c/digit-recognizer/leaderboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utiliser un GAN pour ajouter des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'autre technique de computer vision existentn (GAN, ResNet, Fully Convolutionnal network (for segmentation), transfer learning, LSTM) mais ne sont pas forcement pertinentes sur ce Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
